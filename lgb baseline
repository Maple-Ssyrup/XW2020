#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Jun 24 21:08:52 2020

@author: sallyjiang
"""
#Part 1 EDA + Scenario Classification 

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

## Step A: EDA 
data_path = "~/Documents/2020XW/"
train = pd.read_csv(data_path+'sensor_train.csv')
test = pd.read_csv(data_path+'sensor_test.csv')
#train = pd.read_csv('sensor_train.csv')
#test = pd.read_csv('sensor_test.csv')

label = 'behavior_id'
print('train and test : ({},{})'.format(train.shape, test.shape))

# 1. Check missing value & duplicates
print('Number of duplicates in train: {}'.format(sum(train.duplicated())))
print('Number of duplicates in test : {}'.format(sum(test.duplicated())))

print('We have {} NaN/Null values in train'.format(train.isnull().values.sum()))
print('We have {} NaN/Null values in test'.format(test.isnull().values.sum()))

# 2. Decode 'behavior_id':
# 2.1 
def trans(label):
        mapping = {0: 'A_0', 1: 'A_1', 2: 'A_2', 3: 'A_3', 
        4: 'D_4', 5: 'A_5', 6: 'B_1',7: 'B_5', 
        8: 'B_2', 9: 'B_3', 10: 'B_0', 11: 'A_6', 
        12: 'C_1', 13: 'C_3', 14: 'C_0', 15: 'B_6', 
        16: 'C_2', 17: 'C_5', 18: 'C_6'}
    # 将行为ID转为编码
        code = [mapping[i] for i in label]
        return code

def add_code(df):
    df['code'] = pd.Series(trans(df[label]))
    return df  

train = add_code(train)

# 2.2 Add hand phone infomation (dummy) 
def add_handphone(df):
    handphone = []
    for a in df['code']:
        if a.split("_")[0] == 'D':
            handphone.append(1)
        else:
            handphone.append(0)
    if len(df[label]) == len(handphone):
        df['handphone'] = pd.Series(handphone)
        return df
    else:
        print('ERROR')
        
train = add_handphone(train)

# 2.3 separate 'scenario' and 'motion' from code
train['scenario'] = train.apply(lambda row: row.code.split('_')[0], axis = 1)
train['motion'] = train.apply(lambda row: row.code.split('_')[1], axis = 1)

for col in train.columns: 
    print(col)
train.head(10)

# 3. Visulization 
sns.set_style('whitegrid')
plt.rcParams['font.family'] = 'Dejavu Sans'

# 3.1 Handphone
plt.figure(figsize=(12,6))
plt.title('Data provided by each user', fontsize=20)
sns.countplot(x=label, hue='handphone', data = train) # label!
plt.show()

# 3.2 Motion
plt.figure(figsize=(12,6))
plt.title('Data provided by each user', fontsize=20)
sns.countplot(x='motion', hue='motion', data = train)
plt.show()

# 4. Transformation:

# 4.1 each fragment_id get one record with basic stats 
# trainingset: 
data = train
df = train.drop_duplicates(subset=['fragment_id']).reset_index(drop=True)[['fragment_id', 'behavior_id','motion','handphone','scenario']]

data['acc'] = (data['acc_x'] ** 2 + data['acc_y'] ** 2 + data['acc_z'] ** 2) ** 0.5
data['accg'] = (data['acc_xg'] ** 2 + data['acc_yg'] ** 2 + data['acc_zg'] ** 2) ** 0.5


for f in tqdm([f for f in data.columns if 'acc' in f]):
    for stat in ['min', 'max', 'mean', 'median', 'std', 'skew']:
        df[f+'_'+stat] = data.groupby('fragment_id')[f].agg(stat).values
        
df.head(10)
#testingset
df_test = test.drop_duplicates(subset=['fragment_id']).reset_index(drop=True)[['fragment_id']]

data = test
data['acc'] = (data['acc_x'] ** 2 + data['acc_y'] ** 2 + data['acc_z'] ** 2) ** 0.5
data['accg'] = (data['acc_xg'] ** 2 + data['acc_yg'] ** 2 + data['acc_zg'] ** 2) ** 0.5

from tqdm import tqdm
for f in tqdm([f for f in data.columns if 'acc' in f]):
    for stat in ['min', 'max', 'mean', 'median', 'std', 'skew']:
        df_test[f+'_'+stat] = data.groupby('fragment_id')[f].agg(stat).values
 
df_test.info()

# 4.2 acc/accg mean (by 'motion')
#### From the six-motion perspective, acc is a little bit better than accg

sns.set_palette("Set1", desat=0.80)
facetgrid = sns.FacetGrid(df, hue='motion', height=6,aspect=2)
facetgrid.map(sns.distplot,'acc_mean', hist=False)\
    .add_legend()
plt.show()

sns.set_palette("Set1", desat=0.80)
facetgrid = sns.FacetGrid(df, hue='motion', height=6,aspect=2)
facetgrid.map(sns.distplot,'accg_mean', hist=False)\
    .add_legend()
plt.show()


# 4.3 acc/accg std (by 'motion')
sns.set_palette("Set1", desat=0.80)
facetgrid = sns.FacetGrid(df, hue='motion', size=6,aspect=2)
facetgrid.map(sns.distplot,'acc_std', hist=False)\
    .add_legend()
plt.show()


sns.set_palette("Set1", desat=0.80)
facetgrid = sns.FacetGrid(df, hue='motion', size=6,aspect=2)
facetgrid.map(sns.distplot,'accg_std', hist=False)\
    .add_legend()
plt.show()

# 4.4 Motion
## 1 out numbers other behaviors, 6 is the next 

plt.figure(figsize=(12,6))
plt.title('Data provided by each user', fontsize=20)
sns.countplot(x='motion', hue='motion', data = df)
plt.show()

# 4.5 Scenario  
###### We can see that behavior 1,6,12 (which is A_1, B_1, C_1) out numbers the other type of behaviors
plt.figure(figsize=(16,8))
plt.title('Data provided by each user', fontsize=20)
sns.countplot(x=label, hue='scenario', data = df)
plt.show()


# 4.6 acc/accg mean (by 'scenario')
##### From the scenario perspective, acc is always better than accg !
sns.set_palette("Set1", desat=0.80)
facetgrid = sns.FacetGrid(df, hue='scenario', size=6,aspect=2)
facetgrid.map(sns.distplot,'acc_mean', hist=False)\
    .add_legend()
plt.show()

sns.set_palette("Set1", desat=0.80)
facetgrid = sns.FacetGrid(df, hue='scenario', size=6,aspect=2)
facetgrid.map(sns.distplot,'accg_mean', hist=False)\
    .add_legend()
plt.show()

# 4.7 acc/accg mean (by 'scenario')
sns.set_palette("Set1", desat=0.80)
facetgrid = sns.FacetGrid(df, hue='scenario', size=6,aspect=2)
facetgrid.map(sns.distplot,'acc_std', hist=False)\
    .add_legend()
plt.show()

sns.set_palette("Set1", desat=0.80)
facetgrid = sns.FacetGrid(df, hue='scenario', size=6,aspect=2)
facetgrid.map(sns.distplot,'accg_std', hist=False)\
    .add_legend()
plt.show()

# Step B. Modelling: use acc is key feature to identify D,C and (A+B) 

# 1. Combine A,B as 'AB'
def scenario_3class(scenario):
    if scenario in ['A','B']:
        return 'AB'
    else:
        return scenario
    
df['scenario_3class'] = df.apply(lambda row: scenario_3class(row.scenario), axis = 1)

df.head(10)

# 2. Split Dataset 
del_feature = ['fragment_id','behavior_id','motion','handphone','scenario','scenario_3class']
features = [i for i in df.columns if i not in del_feature]

X = df[features]
Y = df['scenario_3class']
from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.15)

####public test set
X_test_public = df_test.drop(['fragment_id'], axis=1) 

label=['AB','C','D']
print('X_train and y_train : ({},{})'.format(X_train.shape, Y_train.shape))
print('X_test  and Y_test  : ({},{})'.format(X_test.shape, Y_test.shape))


# 3. Some functions  
# 3.1 Confusion Matrix
import itertools
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
plt.rcParams["font.family"] = 'DejaVu Sans'

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=90)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    
    
# 3.2 Generic func
from datetime import datetime
def perform_model(model, X_train, y_train, X_test, y_test, class_labels, cm_normalize=True, \
                 print_cm=True, cm_cmap=plt.cm.Greens):
    
    
    # to store results at various phases
    results = dict()
    
    # time at which model starts training 
    train_start_time = datetime.now()
    print('training the model..')
    model.fit(X_train, y_train)
    print('Done \n \n')
    train_end_time = datetime.now()
    results['training_time'] =  train_end_time - train_start_time
    print('training_time(HH:MM:SS.ms) - {}\n\n'.format(results['training_time']))
    
    
    # predict test data
    print('Predicting test data')
    test_start_time = datetime.now()
    y_pred = model.predict(X_test)
    test_end_time = datetime.now()
    print('Done \n \n')
    results['testing_time'] = test_end_time - test_start_time
    print('testing time(HH:MM:SS:ms) - {}\n\n'.format(results['testing_time']))
    results['predicted'] = y_pred
   

    # calculate overall accuracty of the model
    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_pred)
    # store accuracy in results
    results['accuracy'] = accuracy
    print('---------------------')
    print('|      Accuracy      |')
    print('---------------------')
    print('\n    {}\n\n'.format(accuracy))
    
    
    # confusion matrix
    cm = metrics.confusion_matrix(y_test, y_pred)
    results['confusion_matrix'] = cm
    if print_cm: 
        print('--------------------')
        print('| Confusion Matrix |')
        print('--------------------')
        print('\n {}'.format(cm))
        
    # plot confusin matrix
    plt.figure(figsize=(8,8))
    plt.grid(b=False)
    plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix', cmap = cm_cmap)
    plt.show()
    
    # get classification report
    print('-------------------------')
    print('| Classifiction Report |')
    print('-------------------------')
    classification_report = metrics.classification_report(y_test, y_pred)
    # store report in results
    results['classification_report'] = classification_report
    print(classification_report)
    
    # add the trained  model to the results
    results['model'] = model
    
    return results
   
    
# 3.3 Grid Search
def print_grid_search_attributes(model):
    # Estimator that gave highest score among all the estimators formed in GridSearch
    print('--------------------------')
    print('|      Best Estimator     |')
    print('--------------------------')
    print('\n\t{}\n'.format(model.best_estimator_))


    # parameters that gave best results while performing grid search
    print('--------------------------')
    print('|     Best parameters     |')
    print('--------------------------')
    print('\tParameters of best estimator : \n\n\t{}\n'.format(model.best_params_))


    #  number of cross validation splits
    print('---------------------------------')
    print('|   No of CrossValidation sets   |')
    print('--------------------------------')
    print('\n\tTotal numbre of cross validation sets: {}\n'.format(model.n_splits_))


    # Average cross validated score of the best estimator, from the Grid Search 
    print('--------------------------')
    print('|        Best Score       |')
    print('--------------------------')
    print('\n\tAverage Cross Validate scores of best estimator : \n\n\t{}\n'.format(model.best_score_))
    
    
# 4. Modelling
# 4.1 GBDT  
labels=['AB','C','D']

del_feature = ['fragment_id','behavior_id','motion','handphone','scenario','scenario_3class']
features = [i for i in df.columns if i not in del_feature]

X = df[features]
Y = df['scenario_3class']
from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.15)

####public test set
X_test_public = df_test.drop(['fragment_id'], axis=1) 

print('X_train and y_train : ({},{})'.format(X_train.shape, Y_train.shape))
print('X_test  and Y_test  : ({},{})'.format(X_test.shape, Y_test.shape))

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV
from sklearn import linear_model
from sklearn import metrics

param_grid = {'max_depth': np.arange(5,8,1), \
             'n_estimators':np.arange(130,170,10)}
gbdt = GradientBoostingClassifier()
gbdt_grid = GridSearchCV(gbdt, param_grid=param_grid, cv=3, verbose = 1, n_jobs=-1)
gbdt_grid_results = perform_model(gbdt_grid, X_train, Y_train, X_test, Y_test, class_labels=labels)
print_grid_search_attributes(gbdt_grid_results['model'])

# 4.2 Random Forest
from sklearn.ensemble import RandomForestClassifier
params = {'n_estimators': np.arange(10,201,20), 'max_depth':np.arange(3,15,2)}
rfc = RandomForestClassifier()
rfc_grid = GridSearchCV(rfc, param_grid=params, cv=3, verbose=1, n_jobs=-1)
rfc_grid_results = perform_model(rfc_grid, X_train, Y_train, X_test, Y_test, class_labels=labels)

print_grid_search_attributes(rfc_grid_results['model'])

# 4.3 Prediction: 
## Thus use GBM as the AB,C, D classifier

sub = pd.read_csv('提交结果示例.csv')
print('train and sub and df_test : ({},{},{})'.format(test.shape,sub.shape,df_test.shape))

## predict labels
X_test_public = df_test.drop(['fragment_id'], axis=1) 
pred_scenario_3class = gbdt_grid.predict(X_test_public)
sub['pred_scenario_3class'] = pred_scenario_3class
df_test.head()

## merge test and sub
df_test_3class=pd.merge(df_test,sub,how='inner')
df_test_3class.head(3)


# Step C. Modelling: identify A, B from mixed 'AB'

from sklearn.model_selection import train_test_split
# 1. data
labels = ['A','B']  
df_ab = df[df['scenario_3class'] =='AB']

del_feature = ['fragment_id','behavior_id','motion','handphone','scenario','scenario_3class']

features = [i for i in df.columns if i not in del_feature]

X = df_ab[features]
Y = df_ab['scenario']
from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.15)

####public test set
X_test_public = df_test_3class[df_test_3class['scenario_3class'] =='AB'].drop(['fragment_id'], axis=1) 

X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.15)

#2. Modelling 
# 2.1 Logistic Regression
parameters = {'C':[0.01, 0.1, 1, 10, 20, 30], 'penalty':['l2','l1']}
log_reg = linear_model.LogisticRegression()
log_reg_grid = GridSearchCV(log_reg, param_grid=parameters, cv=3, verbose=1, n_jobs=-1)
log_reg_grid_results =  perform_model(log_reg_grid, X_train, Y_train, X_test, Y_test, class_labels=labels)

# 2.2 Linear SVM
from sklearn.svm import LinearSVC
parameters = {'C':[0.125, 0.5, 1, 2, 8, 16]}
lr_svc = LinearSVC(tol=0.00005)
lr_svc_grid = GridSearchCV(lr_svc, param_grid=parameters, cv=3, verbose=1, n_jobs=-1)
lr_svc_grid_results = perform_model(lr_svc_grid, X_train, Y_train, X_test, Y_test, class_labels=labels)
print_grid_search_attributes(lr_svc_grid_results['model'])

#2.3 Non-linear SVM
from sklearn.svm import SVC
parameters = {'C':[2,8,16],\
              'gamma': [ 0.0078125, 0.125, 2]}
rbf_svm = SVC(kernel='rbf')
rbf_svm_grid = GridSearchCV(rbf_svm,param_grid=parameters, cv=3, verbose=1, n_jobs=-1)

rbf_svm_grid_results = perform_model(rbf_svm_grid, X_train, Y_train, X_test, Y_test, class_labels=labels)

#2.4 Random Forest
from sklearn.ensemble import RandomForestClassifier
params = {'n_estimators': np.arange(10,201,20), 'max_depth':np.arange(3,15,2)}
rfc = RandomForestClassifier()
rfc_grid = GridSearchCV(rfc, param_grid=params, cv=3, verbose=1, n_jobs=-1)
rfc_grid_results = perform_model(rfc_grid, X_train, Y_train, X_test, Y_test, class_labels=labels)

print_grid_search_attributes(rfc_grid_results['model'])

#2.5 Grandient Boosting
from sklearn.ensemble import GradientBoostingClassifier
param_grid = {'max_depth': np.arange(5,8,1), \
             'n_estimators':np.arange(130,170,10)}
gbdt = GradientBoostingClassifier()
gbdt_grid = GridSearchCV(gbdt, param_grid=param_grid, cv=3, verbose=1,n_jobs=-1)
gbdt_grid_results = perform_model(gbdt_grid, X_train, Y_train, X_test, Y_test, class_labels=labels)

print_grid_search_attributes(gbdt_grid_results['model'])

# 2.6 Prediction: 
## Thus choose Grandient Boosting model for A/B Bineary Classification 
df_test_3class.info()
####public test set
X_test_public = df_test_3class[df_test_3class['pred_scenario_3class'] =='AB'].drop(['fragment_id','behavior_id','pred_scenario_3class'], axis=1)
pred_scenario = gbdt_grid.predict(X_test_public)

a = pd.DataFrame(pred_scenario)
f_id = df_test_3class[df_test_3class['pred_scenario_3class'] =='AB']['fragment_id']
a['fragment_id'] = np.array(f_id)
a['pred_scenario']= pred_scenario

a = a.drop(a.columns[0], axis=1)
a.head(10)

sub.head(10)
sub_a = pd.merge(sub,a,how='left')
sub_a['Scenario'] = np.where(sub_a['pred_scenario'].isnull(),sub_a['pred_scenario_3class'], sub_a['pred_scenario'])
sub_a = sub_a.drop(['pred_scenario_3class','pred_scenario'], axis=1)
sub_a.head(10)


    




                     
                     
